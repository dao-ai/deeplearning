WEBVTT

00:00:05.200 --> 00:00:07.200
欢迎来到GPT聊天课程

00:00:07.200 --> 00:00:09.366
为开发人员提供快速工程

00:00:09.366 --> 00:00:11.100
我很高兴能和你在一起

00:00:11.133 --> 00:00:14.466
跟我一起教这个更容易

00:00:14.700 --> 00:00:17.333
她是Open AI的技术人员

00:00:17.333 --> 00:00:20.900
并建立了一个流行的聊天GPT检索插件

00:00:21.100 --> 00:00:23.700
我的大部分工作都是教人

00:00:23.766 --> 00:00:24.566
如何使用

00:00:24.566 --> 00:00:27.800
产品中的技术或大型语言模型

00:00:27.866 --> 00:00:29.766
她还为开放人工智能做出了贡献

00:00:29.766 --> 00:00:31.600
烹饪书，教人们提示

00:00:31.600 --> 00:00:32.800
很高兴能和你在一起

00:00:32.800 --> 00:00:34.266
我很高兴来到这里

00:00:34.266 --> 00:00:37.000
并与大家分享一些激励的最佳实践

00:00:38.333 --> 00:00:39.366
所以有

00:00:39.366 --> 00:00:41.866
网上有很多资料供大家参考

00:00:41.866 --> 00:00:43.166
有这样的文章

00:00:43.266 --> 00:00:45.266
30条每个人都必须知道的提示

00:00:45.800 --> 00:00:48.933
其中很多都集中在聊天GPT上

00:00:48.966 --> 00:00:51.900
许多人正在使用的Web用户界面

00:00:51.900 --> 00:00:53.533
做具体的和经常的

00:00:53.533 --> 00:00:55.533
一次性任务

00:00:55.533 --> 00:00:58.000
我想是洛美鞭子的力量

00:00:58.000 --> 00:01:00.800
语言模型作为一个开发人员

00:01:00.800 --> 00:01:01.800
正在使用API

00:01:01.800 --> 00:01:04.933
调用OMS以快速构建软件应用程序

00:01:04.933 --> 00:01:07.933
我认为这一点还没有得到充分的重视

00:01:08.366 --> 00:01:10.133
实际上是我在AI Fund的团队

00:01:10.133 --> 00:01:12.500
哪家公司是深度学习人工智能的助手

00:01:12.566 --> 00:01:15.400
和很多创业公司合作过吗

00:01:15.466 --> 00:01:18.666
这些技术适用于许多不同的应用

00:01:18.666 --> 00:01:20.566
这是令人兴奋的

00:01:20.666 --> 00:01:23.766
LM api能为开发人员带来什么

00:01:23.766 --> 00:01:25.400
快速构建

00:01:25.900 --> 00:01:27.133
所以在话语中

00:01:27.200 --> 00:01:30.066
我们会和你们分享一些可能性

00:01:30.066 --> 00:01:32.266
你可以做得和最佳实践一样好

00:01:32.266 --> 00:01:33.966
看你怎么做

00:01:34.866 --> 00:01:36.600
有很多东西要讲

00:01:37.000 --> 00:01:38.133
首先你会学到

00:01:38.666 --> 00:01:41.200
一些提示软件开发的最佳实践

00:01:41.266 --> 00:01:43.700
然后我们将介绍一些常见的用例

00:01:43.700 --> 00:01:47.100
总结推断变换展开

00:01:47.100 --> 00:01:49.933
然后你将使用LLM构建一个聊天机器人

00:01:50.466 --> 00:01:52.700
我们希望这会激发你的想象力

00:01:52.700 --> 00:01:54.566
关于您可以构建的新应用程序

00:01:55.300 --> 00:01:58.366
在大型语言模型或LMS的开发中也是如此

00:01:58.366 --> 00:01:59.100
已经带来了

00:01:59.100 --> 00:02:00.733
两种类型的LMS

00:02:00.733 --> 00:02:03.500
我将其称为碱LMS

00:02:03.566 --> 00:02:05.666
指令调整LMS

00:02:06.166 --> 00:02:09.800
所以baselm被训练来预测下一个单词

00:02:09.966 --> 00:02:11.766
基于文本训练数据

00:02:11.766 --> 00:02:13.733
通常在大量数据上训练

00:02:13.800 --> 00:02:15.500
从互联网和其他来源

00:02:15.500 --> 00:02:16.666
求出

00:02:16.700 --> 00:02:18.966
下一个最有可能的词

00:02:19.600 --> 00:02:21.900
例如，如果你要提示这个

00:02:21.966 --> 00:02:24.100
从前有一只独角兽

00:02:24.200 --> 00:02:25.766
它可以完成这个

00:02:25.766 --> 00:02:28.300
也就是说它可以预测接下来的几个词是什么

00:02:28.366 --> 00:02:30.966
住在魔法森林里的所有独角兽朋友

00:02:31.933 --> 00:02:33.666
但如果你用

00:02:33.666 --> 00:02:35.400
法国的首都是哪里

00:02:35.500 --> 00:02:37.400
然后根据什么

00:02:37.666 --> 00:02:40.166
互联网上的文章可能有

00:02:40.166 --> 00:02:42.500
很有可能基地LM

00:02:42.800 --> 00:02:44.200
我将用

00:02:44.600 --> 00:02:45.900
法国哪个城市更大

00:02:45.900 --> 00:02:47.733
法国的人口是多少

00:02:47.966 --> 00:02:49.766
因为网上的文章

00:02:49.766 --> 00:02:53.166
会不会是一个简短的问题列表

00:02:53.266 --> 00:02:54.766
法国这个国家

00:02:55.666 --> 00:02:58.700
相反，一条指令调谐到Om

00:02:58.800 --> 00:03:00.500
这是动力很大的地方吗

00:03:00.500 --> 00:03:03.866
LM的研究和实践一直在进行

00:03:04.200 --> 00:03:04.866
一条指令

00:03:04.866 --> 00:03:07.866
欧姆受过训练，能听从指示

00:03:08.133 --> 00:03:10.600
所以如果你问它法国的首都是哪里

00:03:10.600 --> 00:03:13.166
更有可能输出类似这样的东西

00:03:13.166 --> 00:03:15.400
法国的首都巴黎

00:03:15.900 --> 00:03:18.766
指令调整OMS的方式是典型的

00:03:18.766 --> 00:03:21.566
训练是你从一个基地开始

00:03:21.566 --> 00:03:23.966
不需要训练大量的文本数据

00:03:24.166 --> 00:03:27.133
进一步训练，进一步微调

00:03:27.166 --> 00:03:29.666
输入和输出都是指令

00:03:29.666 --> 00:03:32.533
并努力遵循这些指示

00:03:32.766 --> 00:03:32.966
然后

00:03:32.966 --> 00:03:36.200
通常使用RLHF技术进一步改进

00:03:36.200 --> 00:03:37.366
强化学习

00:03:37.400 --> 00:03:38.666
来自人类的反馈

00:03:38.733 --> 00:03:39.933
来制作这个系统

00:03:40.333 --> 00:03:43.500
能够更好地抱有希望并遵循指示

00:03:43.700 --> 00:03:46.333
因为指令调音师受过训练

00:03:46.366 --> 00:03:48.933
要有希望的荣誉和无害

00:03:49.133 --> 00:03:49.966
举个例子

00:03:49.966 --> 00:03:52.500
他们不太可能输出有问题的东西

00:03:52.533 --> 00:03:55.566
与基础OM相比，有毒输出等技术

00:03:56.000 --> 00:03:57.966
很多实用的用户

00:03:57.966 --> 00:04:00.966
场景已经转向指令系统

00:04:01.333 --> 00:04:03.766
您可以在互联网上找到一些最佳实践

00:04:03.900 --> 00:04:06.333
可能更适合作为基地

00:04:06.366 --> 00:04:08.666
但对于今天的大多数实际应用来说

00:04:08.666 --> 00:04:11.800
我们建议大多数人转而关注

00:04:12.000 --> 00:04:15.266
指令调优的LMS更容易使用

00:04:15.266 --> 00:04:16.100
也

00:04:16.133 --> 00:04:19.800
因为开放AI和其他LM公司的工作

00:04:19.866 --> 00:04:22.100
变得更安全，更团结

00:04:22.866 --> 00:04:23.866
这门课

00:04:23.866 --> 00:04:27.800
将侧重于向联索观察团提供指导的最佳做法

00:04:28.300 --> 00:04:29.866
我们推荐哪一种

00:04:29.900 --> 00:04:32.133
您在大多数应用程序中使用

00:04:32.533 --> 00:04:34.533
在继续之前，我只想承认

00:04:34.533 --> 00:04:37.500
Openai和Deep learning AI的团队

00:04:37.500 --> 00:04:39.800
这促成了材料

00:04:39.900 --> 00:04:41.766
很简单，我来做演示

00:04:41.766 --> 00:04:43.066
我非常感激

00:04:43.100 --> 00:04:45.533
安德鲁缅因乔巴勒莫鲍里斯霍华德

00:04:45.533 --> 00:04:47.733
泰德·森德斯和莉莲一个

00:04:48.000 --> 00:04:49.866
在openai，他们非常投入

00:04:49.866 --> 00:04:51.466
用我们的春季风暴材料

00:04:51.466 --> 00:04:53.066
审查要放在一起的材料

00:04:53.400 --> 00:04:55.400
这是短期课程的正确选择

00:04:55.466 --> 00:04:57.966
在深度学习方面我也很感激

00:04:57.966 --> 00:04:59.500
杰夫·拉德维格的作品

00:04:59.500 --> 00:05:01.200
Eddie Shoe和Tommy Nelson

00:05:01.500 --> 00:05:04.666
所以当你使用调优的Lom指令时

00:05:05.200 --> 00:05:07.733
想想给另一个人下达指令

00:05:08.266 --> 00:05:09.766
说一个聪明的人

00:05:09.766 --> 00:05:12.366
但不知道你任务的细节

00:05:12.533 --> 00:05:14.800
所以当Lom不起作用时

00:05:15.066 --> 00:05:17.100
有时是因为指示不正确

00:05:17.100 --> 00:05:18.566
例如，足够清楚

00:05:18.700 --> 00:05:19.900
如果你说

00:05:19.933 --> 00:05:22.466
请给我写一些关于艾伦·图灵的事

00:05:22.733 --> 00:05:26.500
除此之外，弄清楚是有帮助的

00:05:26.666 --> 00:05:27.766
关于你是否想

00:05:28.166 --> 00:05:30.800
这篇文章把重点放在他的科学工作上

00:05:30.800 --> 00:05:32.666
或者他的个人生活或者他的角色

00:05:32.733 --> 00:05:34.733
在历史或其他方面

00:05:34.966 --> 00:05:36.800
如果你指定

00:05:36.800 --> 00:05:39.600
你想要的文本语气是什么

00:05:39.800 --> 00:05:42.100
应该用专业人士的语气吗

00:05:42.100 --> 00:05:43.166
记者会写道